{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f946ab",
   "metadata": {},
   "source": [
    "Main hypothesis: Banks (morgages) fuel house price increase\n",
    "\n",
    "Exploring: the feedback loop between credit expansion, inequality, and housing prices with an emphasis on whether rising mortgage volumes reflect not just inflation but changing financial behavior and structural inequality\n",
    "\n",
    "Over time, loans have increased, not only due to inflation?\n",
    "1. Idea: Banks are doing bigger risks because they can just own the property after the borrower defaults -> taking away resources -> bigger battle for resources -> price increase -> loans increase because wages didn’t increase\n",
    "-> Formulate a relationship between morgages, inequality and housing price\n",
    "\n",
    "Key Variables:\n",
    "\n",
    "- Housing Prices\n",
    "- Mortgage Credit\n",
    "- Interes Rates\n",
    "- Wages/Income\n",
    "- Inequality\n",
    "- Inflation\n",
    "- Housing Supply\n",
    "\n",
    "\n",
    "Real House Price = nominal house price / CPI\n",
    "Real Mortgage Credit = mortgage credit / CPI\n",
    "Mortgage-to-Income Ratio = total mortgage credit / disposable personal income\n",
    "Debt-Service Ratio = mortgage payments / income\n",
    "Housing Affordability Index = function of income, rates, and home prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "\n",
    "# Read the 'Monthly' sheet from the median_house_price file\n",
    "prices = pd.read_excel(data_path / \"median_house_price.xlsx\", sheet_name=\"Monthly\")\n",
    "# Ensure the date column is datetime\n",
    "if not pd.api.types.is_datetime64_any_dtype(prices[\"observation_date\"]):\n",
    "    prices[\"observation_date\"] = pd.to_datetime(prices[\"observation_date\"])\n",
    "\n",
    "prices.set_axis(prices[\"observation_date\"])  # index by date\n",
    "# Read CPI file and parse dates; adjust column name if different\n",
    "cpi_data = pd.read_excel(\n",
    "    data_path / \"cpi.xlsx\",\n",
    "    sheet_name=\"Monthly\",\n",
    "    parse_dates=[\"observation_date\"]  # ensure this is the actual date column name\n",
    ")\n",
    "\n",
    "# Ensure the date column is datetime\n",
    "if not pd.api.types.is_datetime64_any_dtype(cpi_data[\"observation_date\"]):\n",
    "    cpi_data[\"observation_date\"] = pd.to_datetime(cpi_data[\"observation_date\"])\n",
    "\n",
    "# Filter CPI data to start from 1963-01-01 (inclusive)\n",
    "cpi_data = cpi_data[cpi_data[\"observation_date\"] >= \"1963-01-01\"]\n",
    "\n",
    "# Extract CPI series (column named 'cpi' in the Excel file)\n",
    "cpi = cpi_data[\"cpi\"]\n",
    "\n",
    "# Optional: reset index or keep dates as index\n",
    "cpi = cpi.set_axis(cpi_data[\"observation_date\"])  # index by date if desired\n",
    "\n",
    "# Quick check\n",
    "print(cpi.head())\n",
    "print(f\"Rows after filtering: {len(cpi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cpi.index, cpi.values, label='CPI Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('CPI')\n",
    "plt.title('Consumer Price Index (CPI) Time Series')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear last plot\n",
    "plt.clf()\n",
    "# plot nominal prices\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(prices.index, prices.price, label='Prices Over Time', color='orange')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prices')\n",
    "plt.title('Prices Time Series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cpi_100 = cpi / 100\n",
    "\n",
    "real_prices = prices.price.values / cpi_100.values  # Align CPI to prices index\n",
    "\n",
    "# plot recession periods\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(prices.observation_date, real_prices, label='Real Prices Over Time',color='green')\n",
    "# Highlight recession periods\n",
    "recession_periods = [\n",
    "    (\"1980-01-01\", \"1980-07-01\"),  # Early 1980s recession\n",
    "    (\"1981-07-01\", \"1982-11-01\"),  # Double-dip recession\n",
    "    (\"1990-07-01\", \"1991-03-01\"),  # Early 1990s recession\n",
    "    (\"2001-03-01\", \"2001-11-01\"),  # Dot-com recession\n",
    "    (\"2007-12-01\", \"2009-06-01\"),  # Great Recession\n",
    "    (\"2020-02-01\", \"2020-04-01\")   # COVID-19 recession\n",
    "]\n",
    "for start, end in recession_periods:\n",
    "    plt.axvspan(pd.to_datetime(start), pd.to_datetime(end), color='red', alpha=0.3) # Highlight recession periods\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Real Prices')\n",
    "plt.title('Real Prices Time Series with Recession Periods')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform\n",
    "import numpy as np\n",
    "log_real_prices = np.log(real_prices)\n",
    "# INDEX BY OBSERVATION DATE\n",
    "log_real_prices = pd.Series(log_real_prices, index=prices.observation_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check stationarity with ADF test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_result = adfuller(log_real_prices)\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n",
    "for key, value in adf_result[4].items():\n",
    "    print('Critical Value (%s): %.3f' % (key, value))\n",
    "    \n",
    "# difference prices to make it stationary\n",
    "log_real_prices_diff = pd.Series(log_real_prices).diff().dropna()\n",
    "log_real_prices_diff.index = log_real_prices.index[1:]  # Adjust index after differencing\n",
    "adf_result_diff = adfuller(log_real_prices_diff)\n",
    "print('ADF Statistic (differenced):', adf_result_diff[0])\n",
    "print('p-value (differenced):', adf_result_diff[1])\n",
    "for key, value in adf_result_diff[4].items():\n",
    "    print('Critical Value (%s): %.3f' % (key, value))\n",
    "    \n",
    "    # Basic ACF and PACF plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "plot_acf(log_real_prices_diff, lags=40, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF)')\n",
    "\n",
    "plot_pacf(log_real_prices_diff, lags=40, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "# plot the differenced series\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(log_real_prices_diff.index, log_real_prices_diff.values, label='Differenced Log Real Prices', color='purple')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Differenced Log Real Prices')\n",
    "plt.title('Differenced Log Real Prices Time Series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff9ea0",
   "metadata": {},
   "source": [
    "It's not stationary, so it needs to be differenced. After Differencing it becomes stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# take only last 414 values\n",
    "log_real_prices_diff = log_real_prices_diff[-414:]\n",
    "real_prices = real_prices[-414:]\n",
    "# reindex to ensure proper indexing\n",
    "# log_real_prices_diff = log_real_prices_diff.reset_index(drop=True)\n",
    "# split into train and test sets\n",
    "y_train, y_test = train_test_split(log_real_prices_diff, test_size=0.2, shuffle=False)\n",
    "y_train_original, y_test_original = train_test_split(real_prices, test_size=0.2, shuffle=False)\n",
    "\n",
    "y_train.index = pd.DatetimeIndex(y_train.index.values,\n",
    "                               freq=y_train.index.inferred_freq)\n",
    "print(f\"Training set length: {len(y_train)}\")\n",
    "print(f\"Test set length: {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d18d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# ARIMA(p, d, q) where:\n",
    "# p = AR lags (2 in your case)\n",
    "# d = differencing order (0 if your data is already stationary)\n",
    "# q = MA terms (0 for no MA)\n",
    "\n",
    "\n",
    "\n",
    "model = ARIMA(y_train, order=(3, 0, 0))\n",
    "results = model.fit()\n",
    "\n",
    "# View results\n",
    "print(results.summary())\n",
    "results.plot_diagnostics(figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a067d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check AR roots\n",
    "ar_roots = results.arroots\n",
    "seasonal_roots = results.seasonalarroots if hasattr(results, 'seasonalarroots') else []\n",
    "\n",
    "print(\"AR roots:\", ar_roots)\n",
    "print(\"All AR roots outside unit circle?\", all(abs(r) > 1 for r in ar_roots))\n",
    "\n",
    "if len(seasonal_roots) > 0:\n",
    "    print(\"Seasonal roots:\", seasonal_roots)\n",
    "    print(\"All seasonal roots outside unit circle?\", \n",
    "          all(abs(r) > 1 for r in seasonal_roots))\n",
    "\n",
    "# Visualize\n",
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "results.plot_diagnostics(figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb493a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "p = range(0, 10)\n",
    "\n",
    "\n",
    "aic_table = []\n",
    "bic_table = []\n",
    "results = []\n",
    "\n",
    "for i in p:\n",
    "    try:\n",
    "        model = ARIMA(y_train, order=(i,0,0))\n",
    "        results = model.fit()\n",
    "        aic_table.append((i,0,0, results.aic))\n",
    "        bic_table.append((i,0,0, results.bic))\n",
    "        results.append(results)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "aic_df = pd.DataFrame(aic_table, columns=[\"p\",\"d\",\"q\",\"AIC\"])\n",
    "bic_df = pd.DataFrame(bic_table, columns=[\"p\",\"d\",\"q\",\"BIC\"])\n",
    "print(aic_df.sort_values(\"AIC\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for p_value in p:\n",
    "    aic = aic_df[aic_df['d'] == p_value]\n",
    "    bic = bic_df[bic_df['d'] == p_value]\n",
    "\n",
    "    plt.plot(aic['p'], aic['AIC'], color='blue')\n",
    "    plt.plot(bic['p'], bic['BIC'], color='red')\n",
    "\n",
    "# Add legend using proxy artists\n",
    "plt.plot([], [], color='blue', label='AIC')\n",
    "plt.plot([], [], color='red', label='BIC')\n",
    "\n",
    "plt.xlabel('p values')\n",
    "plt.ylabel('AIC and BIC')\n",
    "plt.title('AIC and BIC for different lag values')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97dbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an arima 3,0,0 model based on the aic and bic results\n",
    "model = ARIMA(y_train, order=(3,0,0))\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "results.plot_diagnostics(figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24631f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_ar3_features(y, lag=3):\n",
    "    \"\"\"\n",
    "    Create lagged features for AR(3) model\n",
    "    Returns X (lagged features) and y (target values)\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    X = np.zeros((n - lag, lag))\n",
    "    y_target = np.zeros(n - lag)\n",
    "    \n",
    "    for i in range(lag, n):\n",
    "        X[i - lag] = [y[i-1], y[i-2], y[i-3]]\n",
    "        y_target[i - lag] = y[i]\n",
    "    \n",
    "    return X, y_target\n",
    "\n",
    "\n",
    "def fit_ar3(y_train):\n",
    "    \"\"\"\n",
    "    Fit AR(3) model using OLS\n",
    "    Returns coefficients [phi1, phi2, phi3, intercept]\n",
    "    \"\"\"\n",
    "    X, y_target = create_ar3_features(y_train, lag=3)\n",
    "    \n",
    "    # Add intercept\n",
    "    X_with_intercept = np.column_stack([X, np.ones(len(X))])\n",
    "    \n",
    "    # OLS estimation: beta = (X'X)^(-1) X'y\n",
    "    coeffs = np.linalg.lstsq(X_with_intercept, y_target, rcond=None)[0]\n",
    "    \n",
    "    return coeffs  # [phi1, phi2, phi3, intercept]\n",
    "\n",
    "\n",
    "def predict_ar3(y_history, coeffs, steps=1):\n",
    "    \"\"\"\n",
    "    Predict next value(s) using AR(3) model\n",
    "    y_history: array of recent observations (at least last 3 values)\n",
    "    coeffs: [phi1, phi2, phi3, intercept]\n",
    "    steps: number of steps to forecast\n",
    "    \"\"\"\n",
    "    y_history = np.array(y_history).flatten()\n",
    "    predictions = []\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    history = list(y_history[-3:])  # Keep last 3 values\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        # AR(3): y_t = phi1*y_{t-1} + phi2*y_{t-2} + phi3*y_{t-3} + c\n",
    "        pred = (coeffs[0] * history[-1] + \n",
    "                coeffs[1] * history[-2] + \n",
    "                coeffs[2] * history[-3] + \n",
    "                coeffs[3])\n",
    "        \n",
    "        predictions.append(pred)\n",
    "        history.append(pred)  # Update history with prediction\n",
    "        \n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "def rolling_window_forecast(y, window_size, test_size):\n",
    "    \"\"\"\n",
    "    Rolling window: Fixed-size training window that slides forward\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    train_end = n - test_size\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for i in range(train_end, n):\n",
    "        # Define rolling window\n",
    "        start_idx = max(0, i - window_size)\n",
    "        end_idx = i\n",
    "        \n",
    "        # Train on rolling window\n",
    "        y_train = y[start_idx:end_idx]\n",
    "        \n",
    "        # Test on next observation\n",
    "        y_test = y[i]\n",
    "        \n",
    "        # Fit AR(3) and predict\n",
    "        coeffs = fit_ar3(y_train)\n",
    "        pred = predict_ar3(y_train, coeffs, steps=1)[0]\n",
    "        \n",
    "        predictions.append(pred)\n",
    "        actuals.append(y_test)\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "\n",
    "def expanding_window_forecast(y, initial_train_size, test_size):\n",
    "    \"\"\"\n",
    "    Expanding window: Training set grows with each iteration\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    train_end = n - test_size\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    for i in range(train_end, n):\n",
    "        # Expanding window: from start to current point\n",
    "        y_train = y[:i]\n",
    "        \n",
    "        # Test on next observation\n",
    "        y_test = y[i]\n",
    "        \n",
    "        # Fit AR(3) and predict\n",
    "        coeffs = fit_ar3(y_train)\n",
    "        pred = predict_ar3(y_train, coeffs, steps=1)[0]\n",
    "        \n",
    "        predictions.append(pred)\n",
    "        actuals.append(y_test)\n",
    "    \n",
    "    return np.array(predictions), np.array(actuals)\n",
    "\n",
    "\n",
    "def one_step_forecast(y, train_size):\n",
    "    \"\"\"\n",
    "    One-step ahead: Train once, predict all test observations sequentially\n",
    "    Uses true observed values for each prediction (not forecasted values)\n",
    "    \"\"\"\n",
    "    # Split data\n",
    "    y_train = y[:train_size]\n",
    "    y_test = y[train_size:]\n",
    "    \n",
    "    # Train once\n",
    "    coeffs = fit_ar3(y_train)\n",
    "    \n",
    "    # Predict each test observation using actual historical values\n",
    "    predictions = []\n",
    "    for i in range(len(y_test)):\n",
    "        # Use actual values from history (not predictions)\n",
    "        if i == 0:\n",
    "            history = y_train[-3:]\n",
    "        elif i == 1:\n",
    "            history = np.concatenate([y_train[-2:], [y[train_size]]])\n",
    "        elif i == 2:\n",
    "            history = np.concatenate([y_train[-1:], y[train_size:train_size+2]])\n",
    "        else:\n",
    "            history = y[train_size+i-3:train_size+i]\n",
    "        \n",
    "        pred = predict_ar3(history, coeffs, steps=1)[0]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions), y_test\n",
    "\n",
    "\n",
    "def evaluate_forecast(predictions, actuals, scheme_name):\n",
    "    \"\"\"\n",
    "    Calculate and display forecast metrics\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    mape = np.mean(np.abs((actuals - predictions) / actuals)) * 100\n",
    "    \n",
    "    results = {\n",
    "        'Scheme': scheme_name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2,\n",
    "        'MAPE (%)': mape,\n",
    "        'N_predictions': len(predictions)\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# -----------------\n",
    "# Assuming you have y_train and y_test defined\n",
    "# Combine them for the forecasting schemes\n",
    "y = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Set parameters\n",
    "window_size = 100  # for rolling window\n",
    "test_size = len(y_test)  # number of observations to forecast\n",
    "initial_train_size = len(y_train)  # for expanding and one-step\n",
    "\n",
    "print(\"Running AR(3) Forecasting Schemes...\")\n",
    "print(f\"Total observations: {len(y)}\")\n",
    "print(f\"Training size: {initial_train_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "print()\n",
    "\n",
    "# Run all three schemes\n",
    "print(\"Running Rolling Window Forecast...\")\n",
    "rolling_pred, rolling_actual = rolling_window_forecast(y, window_size, test_size)\n",
    "\n",
    "print(\"Running Expanding Window Forecast...\")\n",
    "expanding_pred, expanding_actual = expanding_window_forecast(y, initial_train_size, test_size)\n",
    "\n",
    "print(\"Running One-Step Forecast...\")\n",
    "onestep_pred, onestep_actual = one_step_forecast(y, initial_train_size)\n",
    "\n",
    "# Evaluate all schemes\n",
    "results = []\n",
    "results.append(evaluate_forecast(rolling_pred, rolling_actual, 'Rolling Window'))\n",
    "results.append(evaluate_forecast(expanding_pred, expanding_actual, 'Expanding Window'))\n",
    "results.append(evaluate_forecast(onestep_pred, onestep_actual, 'One-Step'))\n",
    "\n",
    "# Create comparison table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AR(3) FORECASTING SCHEMES COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "schemes = [\n",
    "    ('Rolling Window', rolling_pred, rolling_actual),\n",
    "    ('Expanding Window', expanding_pred, expanding_actual),\n",
    "    ('One-Step', onestep_pred, onestep_actual)\n",
    "]\n",
    "\n",
    "for idx, (name, pred, actual) in enumerate(schemes):\n",
    "    ax = axes[idx]\n",
    "    time_index = range(len(pred))\n",
    "    \n",
    "    ax.plot(time_index, actual, label='Actual', color='blue', linewidth=2)\n",
    "    ax.plot(time_index, pred, label='Predicted', color='red', linestyle='--', linewidth=2)\n",
    "    ax.fill_between(time_index, actual, pred, alpha=0.3)\n",
    "    \n",
    "    ax.set_title(f'{name} - RMSE: {np.sqrt(mean_squared_error(actual, pred)):.2f}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Time Period')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ar3_forecast_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Forecast errors comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "errors_rolling = rolling_actual - rolling_pred\n",
    "errors_expanding = expanding_actual - expanding_pred\n",
    "errors_onestep = onestep_actual - onestep_pred\n",
    "\n",
    "time_index = range(len(errors_rolling))\n",
    "\n",
    "ax.plot(time_index, errors_rolling, label='Rolling Window', alpha=0.7)\n",
    "ax.plot(time_index, errors_expanding, label='Expanding Window', alpha=0.7)\n",
    "ax.plot(time_index, errors_onestep, label='One-Step', alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_title('AR(3) Forecast Errors Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Time Period')\n",
    "ax.set_ylabel('Forecast Error')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ar3_forecast_errors.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualizations saved as 'ar3_forecast_comparison.png' and 'ar3_forecast_errors.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# =============================================================================\n",
    "# DIAGNOSTICS FOR AR(3) FORECASTS\n",
    "# =============================================================================\n",
    "\n",
    "def run_diagnostics(predictions, actuals, scheme_name, coeffs=None):\n",
    "    \"\"\"\n",
    "    Run diagnostic tests and print results\n",
    "    \"\"\"\n",
    "    residuals = actuals - predictions\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"DIAGNOSTICS: {scheme_name}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nMean: {np.mean(residuals):.6f} | Std: {np.std(residuals):.6f}\")\n",
    "    \n",
    "    # Normality test\n",
    "    _, jb_p = stats.jarque_bera(residuals)\n",
    "    print(f\"Jarque-Bera p-value: {jb_p:.4f} {'✓ Normal' if jb_p > 0.05 else '✗ Not normal'}\")\n",
    "    \n",
    "    # Autocorrelation test\n",
    "    lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
    "    lb_p = lb_test.iloc[0]['lb_pvalue']\n",
    "    print(f\"Ljung-Box p-value: {lb_p:.4f} {'✓ No autocorr' if lb_p > 0.05 else '✗ Autocorr detected'}\")\n",
    "    \n",
    "    # Durbin-Watson\n",
    "    dw = durbin_watson(residuals)\n",
    "    print(f\"Durbin-Watson: {dw:.4f} (2=no autocorr, <2=pos, >2=neg)\")\n",
    "    \n",
    "    # Heteroskedasticity\n",
    "    _, levene_p = stats.levene(residuals[:len(residuals)//2], residuals[len(residuals)//2:])\n",
    "    print(f\"Levene's p-value: {levene_p:.4f} {'✓ Homoskedastic' if levene_p > 0.05 else '✗ Heteroskedastic'}\")\n",
    "    \n",
    "    # Stability check\n",
    "    if coeffs is not None:\n",
    "        poly_coeffs = [coeffs[2], coeffs[1], coeffs[0], -1]\n",
    "        roots = np.roots(poly_coeffs)\n",
    "        abs_roots = np.abs(roots)\n",
    "        stable = all(abs_roots > 1)\n",
    "        print(f\"\\nAR(3) Coefficients: φ₁={coeffs[0]:.4f}, φ₂={coeffs[1]:.4f}, φ₃={coeffs[2]:.4f}\")\n",
    "        print(f\"Stability: {'✓ STABLE' if stable else '✗ UNSTABLE'} (roots: {abs_roots})\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# Run diagnostics for each scheme\n",
    "print(\"\\n\" + \"█\"*70)\n",
    "print(\"AR(3) FORECAST DIAGNOSTICS\")\n",
    "print(\"█\"*70 + \"\\n\")\n",
    "\n",
    "# Rolling Window\n",
    "run_diagnostics(rolling_pred, rolling_actual, \"Rolling Window\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "residuals_rolling = rolling_actual - rolling_pred\n",
    "\n",
    "# Time series plot\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.plot(residuals_rolling, color='navy', alpha=0.7)\n",
    "ax1.axhline(y=0, color='red', linestyle='--')\n",
    "ax1.set_title('Residuals: Rolling Window')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram + Q-Q\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.hist(residuals_rolling, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "mu, std = np.mean(residuals_rolling), np.std(residuals_rolling)\n",
    "x = np.linspace(residuals_rolling.min(), residuals_rolling.max(), 100)\n",
    "ax2.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2)\n",
    "ax2.set_title('Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "stats.probplot(residuals_rolling, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# ACF/PACF\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "plot_acf(residuals_rolling, lags=min(30, len(residuals_rolling)//4), ax=ax4, alpha=0.05)\n",
    "ax4.set_title('ACF')\n",
    "\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "plot_pacf(residuals_rolling, lags=min(30, len(residuals_rolling)//4), ax=ax5, alpha=0.05, method='ywm')\n",
    "ax5.set_title('PACF')\n",
    "\n",
    "# Residuals vs Fitted\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.scatter(rolling_pred, residuals_rolling, alpha=0.5)\n",
    "ax6.axhline(y=0, color='red', linestyle='--')\n",
    "ax6.set_title('Residuals vs Fitted')\n",
    "ax6.set_xlabel('Fitted')\n",
    "ax6.set_ylabel('Residuals')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('diagnostics_rolling.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Expanding Window\n",
    "run_diagnostics(expanding_pred, expanding_actual, \"Expanding Window\")\n",
    "residuals_expanding = expanding_actual - expanding_pred\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.plot(residuals_expanding, color='navy', alpha=0.7)\n",
    "ax1.axhline(y=0, color='red', linestyle='--')\n",
    "ax1.set_title('Residuals: Expanding Window')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.hist(residuals_expanding, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "mu, std = np.mean(residuals_expanding), np.std(residuals_expanding)\n",
    "x = np.linspace(residuals_expanding.min(), residuals_expanding.max(), 100)\n",
    "ax2.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2)\n",
    "ax2.set_title('Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "stats.probplot(residuals_expanding, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "plot_acf(residuals_expanding, lags=min(30, len(residuals_expanding)//4), ax=ax4, alpha=0.05)\n",
    "ax4.set_title('ACF')\n",
    "\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "plot_pacf(residuals_expanding, lags=min(30, len(residuals_expanding)//4), ax=ax5, alpha=0.05, method='ywm')\n",
    "ax5.set_title('PACF')\n",
    "\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.scatter(expanding_pred, residuals_expanding, alpha=0.5)\n",
    "ax6.axhline(y=0, color='red', linestyle='--')\n",
    "ax6.set_title('Residuals vs Fitted')\n",
    "ax6.set_xlabel('Fitted')\n",
    "ax6.set_ylabel('Residuals')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('diagnostics_expanding.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# One-Step (with stability check)\n",
    "# Get coefficients for stability analysis\n",
    "def fit_ar3(y_train):\n",
    "    def create_ar3_features(y, lag=3):\n",
    "        n = len(y)\n",
    "        X = np.zeros((n - lag, lag))\n",
    "        y_target = np.zeros(n - lag)\n",
    "        for i in range(lag, n):\n",
    "            X[i - lag] = [y[i-1], y[i-2], y[i-3]]\n",
    "            y_target[i - lag] = y[i]\n",
    "        return X, y_target\n",
    "    \n",
    "    X, y_target = create_ar3_features(y_train, lag=3)\n",
    "    X_with_intercept = np.column_stack([X, np.ones(len(X))])\n",
    "    coeffs = np.linalg.lstsq(X_with_intercept, y_target, rcond=None)[0]\n",
    "    return coeffs\n",
    "\n",
    "y_combined = np.concatenate([y_train, y_test])\n",
    "coeffs_onestep = fit_ar3(y_combined[:len(y_train)])\n",
    "\n",
    "run_diagnostics(onestep_pred, onestep_actual, \"One-Step\", coeffs=coeffs_onestep)\n",
    "residuals_onestep = onestep_actual - onestep_pred\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.plot(residuals_onestep, color='navy', alpha=0.7)\n",
    "ax1.axhline(y=0, color='red', linestyle='--')\n",
    "ax1.set_title('Residuals: One-Step')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.hist(residuals_onestep, bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "mu, std = np.mean(residuals_onestep), np.std(residuals_onestep)\n",
    "x = np.linspace(residuals_onestep.min(), residuals_onestep.max(), 100)\n",
    "ax2.plot(x, stats.norm.pdf(x, mu, std), 'r-', linewidth=2)\n",
    "ax2.set_title('Distribution')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "stats.probplot(residuals_onestep, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "plot_acf(residuals_onestep, lags=min(30, len(residuals_onestep)//4), ax=ax4, alpha=0.05)\n",
    "ax4.set_title('ACF')\n",
    "\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "plot_pacf(residuals_onestep, lags=min(30, len(residuals_onestep)//4), ax=ax5, alpha=0.05, method='ywm')\n",
    "ax5.set_title('PACF')\n",
    "\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.scatter(onestep_pred, residuals_onestep, alpha=0.5)\n",
    "ax6.axhline(y=0, color='red', linestyle='--')\n",
    "ax6.set_title('Residuals vs Fitted')\n",
    "ax6.set_xlabel('Fitted')\n",
    "ax6.set_ylabel('Residuals')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('diagnostics_onestep.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Diagnostics complete! Plots saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfab548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# INVERSE TRANSFORMATION: Log-Differencing to Real Prices\n",
    "# =============================================================================\n",
    "\n",
    "def inverse_log_diff(predictions, last_known_price):\n",
    "    \"\"\"\n",
    "    Transform log-differenced predictions back to real prices\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : array-like\n",
    "        AR(3) predictions in log-differenced space\n",
    "    last_known_price : float\n",
    "        The last known actual price before the forecast period\n",
    "        (this is needed to reconstruct the price level)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    real_prices : array\n",
    "        Predictions transformed back to real price levels\n",
    "    \n",
    "    Note:\n",
    "    -----\n",
    "    If you did: log_diff = log(price[t]) - log(price[t-1])\n",
    "    Then: price[t] = price[t-1] * exp(log_diff[t])\n",
    "    \"\"\"\n",
    "    predictions = np.array(predictions)\n",
    "    real_prices = np.zeros(len(predictions))\n",
    "    \n",
    "    # First prediction\n",
    "    real_prices[0] = last_known_price * np.exp(predictions[0])\n",
    "    \n",
    "    # Subsequent predictions (cumulative)\n",
    "    for i in range(1, len(predictions)):\n",
    "        real_prices[i] = real_prices[i-1] * np.exp(predictions[i])\n",
    "    \n",
    "    return real_prices\n",
    "\n",
    "\n",
    "def inverse_transform_all_schemes(rolling_pred, expanding_pred, onestep_pred, \n",
    "                                   y_train_original, y_test_original):\n",
    "    \"\"\"\n",
    "    Transform all three forecasting schemes back to real prices\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rolling_pred, expanding_pred, onestep_pred : arrays\n",
    "        Predictions in log-differenced space\n",
    "    y_train_original : array\n",
    "        Original training prices (NOT log-differenced)\n",
    "    y_test_original : array\n",
    "        Original test prices (NOT log-differenced) for comparison\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dictionary with transformed predictions and actuals\n",
    "    \"\"\"\n",
    "    # Last known price from training set\n",
    "    last_known_price = y_train_original[-1]\n",
    "    \n",
    "    # Transform predictions\n",
    "    rolling_real = inverse_log_diff(rolling_pred, last_known_price)\n",
    "    expanding_real = inverse_log_diff(expanding_pred, last_known_price)\n",
    "    onestep_real = inverse_log_diff(onestep_pred, last_known_price)\n",
    "    \n",
    "    results = {\n",
    "        'rolling': rolling_real,\n",
    "        'expanding': expanding_real,\n",
    "        'onestep': onestep_real,\n",
    "        'actual': y_test_original\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "# Assuming you have:\n",
    "# - y_train_original: original prices before log-differencing\n",
    "# - y_test_original: original test prices\n",
    "# - rolling_pred, expanding_pred, onestep_pred: predictions in log-diff space\n",
    "\n",
    "# Transform back to real prices\n",
    "real_predictions = inverse_transform_all_schemes(\n",
    "    rolling_pred, \n",
    "    expanding_pred, \n",
    "    onestep_pred,\n",
    "    y_train_original,\n",
    "    y_test_original\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "rolling_real = real_predictions['rolling']\n",
    "expanding_real = real_predictions['expanding']\n",
    "onestep_real = real_predictions['onestep']\n",
    "actual_prices = real_predictions['actual']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREDICTIONS TRANSFORMED TO REAL PRICES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nLast training price: ${y_train_original[-1]:,.2f}\")\n",
    "print(f\"First test price: ${y_test_original[0]:,.2f}\")\n",
    "print(f\"\\nFirst predictions (real prices):\")\n",
    "print(f\"  Rolling Window:  ${rolling_real[0]:,.2f}\")\n",
    "print(f\"  Expanding Window: ${expanding_real[0]:,.2f}\")\n",
    "print(f\"  One-Step:        ${onestep_real[0]:,.2f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate errors in real price space\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def calculate_real_price_metrics(pred, actual):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mape = np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R²': r2}\n",
    "\n",
    "# Metrics in real price space\n",
    "print(\"\\nMETRICS IN REAL PRICE SPACE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_rolling = calculate_real_price_metrics(rolling_real, actual_prices)\n",
    "metrics_expanding = calculate_real_price_metrics(expanding_real, actual_prices)\n",
    "metrics_onestep = calculate_real_price_metrics(onestep_real, actual_prices)\n",
    "\n",
    "results_df = pd.DataFrame([\n",
    "    {'Scheme': 'Rolling', **metrics_rolling},\n",
    "    {'Scheme': 'Expanding', **metrics_expanding},\n",
    "    {'Scheme': 'One-Step', **metrics_onestep}\n",
    "])\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# =============================================================================\n",
    "# VISUALIZATION: Real Prices\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "schemes_real = [\n",
    "    ('Rolling Window', rolling_real),\n",
    "    ('Expanding Window', expanding_real),\n",
    "    ('One-Step', onestep_real)\n",
    "]\n",
    "\n",
    "for idx, (name, pred) in enumerate(schemes_real):\n",
    "    ax = axes[idx]\n",
    "    time_index = range(len(pred))\n",
    "    \n",
    "    ax.plot(time_index, actual_prices, label='Actual', \n",
    "            color='blue', linewidth=2.5, marker='o', markersize=4)\n",
    "    ax.plot(time_index, pred, label='Predicted', \n",
    "            color='red', linestyle='--', linewidth=2.5, marker='s', markersize=4)\n",
    "    ax.fill_between(time_index, actual_prices, pred, alpha=0.2)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(actual_prices, pred))\n",
    "    mae = mean_absolute_error(actual_prices, pred)\n",
    "    \n",
    "    ax.set_title(f'{name} - RMSE: ${rmse:,.2f} | MAE: ${mae:,.2f}', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Time Period', fontsize=11)\n",
    "    ax.set_ylabel('Price ($)', fontsize=11)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "plt.suptitle('AR(3) Forecasts in Real Price Space', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('forecast_real_prices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Comparison plot\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "time_index = range(len(actual_prices))\n",
    "ax.plot(time_index, actual_prices, label='Actual', \n",
    "        color='black', linewidth=3, marker='o', markersize=5)\n",
    "ax.plot(time_index, rolling_real, label='Rolling Window', \n",
    "        alpha=0.7, linewidth=2, marker='s', markersize=4)\n",
    "ax.plot(time_index, expanding_real, label='Expanding Window', \n",
    "        alpha=0.7, linewidth=2, marker='^', markersize=4)\n",
    "ax.plot(time_index, onestep_real, label='One-Step', \n",
    "        alpha=0.7, linewidth=2, marker='d', markersize=4)\n",
    "\n",
    "ax.set_title('All Forecasting Schemes - Real Prices', fontsize=15, fontweight='bold')\n",
    "ax.set_xlabel('Time Period', fontsize=12)\n",
    "ax.set_ylabel('Price ($)', fontsize=12)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('forecast_all_schemes_real_prices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Transformation complete! Plots saved.\")\n",
    "print(\"  - forecast_real_prices.png\")\n",
    "print(\"  - forecast_all_schemes_real_prices.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
